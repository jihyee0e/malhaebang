{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"ÏÉÅÌÉú ÏΩîÎìú: {res.status_code}\")\n",
    "# print(\"ÏùëÎãµ ÎÇ¥Ïö© ÏùºÎ∂Ä:\", res.text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import traceback\n",
    "import re\n",
    "import sqlite3\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import codecs\n",
    "import time\n",
    "from urllib.parse import urlencode\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "# ====== Îèô Î¶¨Ïä§Ìä∏ Ï§ÄÎπÑ ======\n",
    "with open(\"dong_dict.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dong_dict = json.load(f)\n",
    "\n",
    "# ====== Ïø†ÌÇ§, Ìó§Îçî Ï§ÄÎπÑ ======\n",
    "with open(\"secrets.json\", \"r\") as f:\n",
    "    secret = json.load(f)\n",
    "    \n",
    "cookies = secrets[\"cookies\"]\n",
    "headers = secrets[\"headers\"]\n",
    "    \n",
    "def get_articles(cortar_no, page):\n",
    "    params = {\n",
    "        'realEstateType': 'APT:OPST:ABYG:OBYG:GM:OR:DDDGG:JWJT:SGJT:HOJT:VL:YR:DSD:YR:DSD:YR:DSD',\n",
    "        'tradeType': '',\n",
    "        'order': 'rank',\n",
    "        'cortarNo': cortar_no,\n",
    "        'tag': ':::::::SMALLSPCRENT:',\n",
    "        'rentPriceMin': '0',\n",
    "        'rentPriceMax': '900000000',\n",
    "        'priceMin': '0',\n",
    "        'priceMax': '900000000',\n",
    "        'areaMin': '0',\n",
    "        'areaMax': '900000000',\n",
    "        'showArticle': 'false',\n",
    "        'sameAddressGroup': 'false',\n",
    "        'priceType': 'RETAIL',\n",
    "        'page': str(page)\n",
    "    }\n",
    "\n",
    "    url = f\"https://new.land.naver.com/api/articles?{urlencode(params)}\"\n",
    "    resp = requests.get(url, headers=headers, cookies=cookies)\n",
    "    return resp.json().get(\"articleList\", [])\n",
    "\n",
    "def get_detail(article_no):\n",
    "    url = f\"https://new.land.naver.com/api/articles/{article_no}\"\n",
    "    resp = requests.get(url, headers=headers, cookies=cookies)\n",
    "    return resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è ÎØ∏ÏïÑÎèô Îß§Î¨º ÏãúÏûë\n",
      "‚úÖ ÎØ∏ÏïÑÎèô ÌÅ¥Î¶≠ ÏôÑÎ£å\n",
      "[ÎØ∏ÏïÑÎèô] 1Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[ÎØ∏ÏïÑÎèô] 2Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[ÎØ∏ÏïÑÎèô] 3Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "üíæ ÎØ∏ÏïÑÎèô DB Ï†ÄÏû• ÏôÑÎ£å\n",
      "‚ñ∂Ô∏è Î≤àÎèô Îß§Î¨º ÏãúÏûë\n",
      "‚úÖ Î≤àÎèô ÌÅ¥Î¶≠ ÏôÑÎ£å\n",
      "[Î≤àÎèô] 1Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[Î≤àÎèô] 2Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[Î≤àÎèô] 3Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "üíæ Î≤àÎèô DB Ï†ÄÏû• ÏôÑÎ£å\n",
      "‚ñ∂Ô∏è ÏàòÏú†Îèô Îß§Î¨º ÏãúÏûë\n",
      "‚úÖ ÏàòÏú†Îèô ÌÅ¥Î¶≠ ÏôÑÎ£å\n",
      "[ÏàòÏú†Îèô] 1Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[ÏàòÏú†Îèô] 2Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[ÏàòÏú†Îèô] 3Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "üíæ ÏàòÏú†Îèô DB Ï†ÄÏû• ÏôÑÎ£å\n",
      "‚ñ∂Ô∏è Ïö∞Ïù¥Îèô Îß§Î¨º ÏãúÏûë\n",
      "‚úÖ Ïö∞Ïù¥Îèô ÌÅ¥Î¶≠ ÏôÑÎ£å\n",
      "[Ïö∞Ïù¥Îèô] 1Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[Ïö∞Ïù¥Îèô] 2Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "[Ïö∞Ïù¥Îèô] 3Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\n",
      "üíæ Ïö∞Ïù¥Îèô DB Ï†ÄÏû• ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# ====== ÎÑ§Ïù¥Î≤Ñ Î∂ÄÎèôÏÇ∞ Ï†ëÏÜç ÌõÑ Ï§ÄÎπÑ ======\n",
    "driver.get(\"https://new.land.naver.com/complexes\")\n",
    "time.sleep(2)\n",
    "\n",
    "# ÏõêÎ£∏/Ìà¨Î£∏ Î≤ÑÌäº ÌÅ¥Î¶≠\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div/div[1]/a[3]'))).click()\n",
    "time.sleep(1)\n",
    "\n",
    "# ====== Íµ¨, ÎèôÎ≥ÑÎ°ú ÎèåÎ©¥ÏÑú Îß§Î¨º ÌÅ¨Î°§ÎßÅ ======\n",
    "target_gu_list = [\"Í∞ïÎÇ®Íµ¨\", \"Í∞ïÎèôÍµ¨\", \"Í∞ïÎ∂ÅÍµ¨\", \"Í∞ïÏÑúÍµ¨\", \"Í¥ÄÏïÖÍµ¨\"]  # a\n",
    "# target_gu_list = [\"Í¥ëÏßÑÍµ¨\", \"Íµ¨Î°úÍµ¨\", \"Í∏àÏ≤úÍµ¨\", \"ÎÖ∏ÏõêÍµ¨\", \"ÎèÑÎ¥âÍµ¨\"]  # b\n",
    "# target_gu_list = [\"ÎèôÎåÄÎ¨∏Íµ¨\", \"ÎèôÏûëÍµ¨\", \"ÎßàÌè¨Íµ¨\", \"ÏÑúÎåÄÎ¨∏Íµ¨\", \"ÏÑúÏ¥àÍµ¨\"]  # c\n",
    "# target_gu_list = [\"ÏÑ±ÎèôÍµ¨\", \"ÏÑ±Î∂ÅÍµ¨\", \"ÏÜ°ÌååÍµ¨\", \"ÏñëÏ≤úÍµ¨\", \"ÏòÅÎì±Ìè¨Íµ¨\"]  # d\n",
    "# target_gu_list = [\"Ïö©ÏÇ∞Íµ¨\", \"ÏùÄÌèâÍµ¨\", \"Ï¢ÖÎ°úÍµ¨\", \"Ï§ëÍµ¨\", \"Ï§ëÎûëÍµ¨\"]  # e\n",
    "# target_gu_list = ['Í∞ïÎ∂ÅÍµ¨']  # testÏö©\n",
    "\n",
    "for target_gu in target_gu_list:\n",
    "    dong_list = dong_dict.get(target_gu, [])\n",
    "\n",
    "    for dong_code, dong_name in dong_list:\n",
    "        try:\n",
    "            print(f\"‚ñ∂Ô∏è {dong_name} Îß§Î¨º ÏãúÏûë\")\n",
    "\n",
    "            titles, prices, addresses = [], [], []\n",
    "            floors, d_types, m_fees = [], [], []\n",
    "            a_froms, nums, agent_comms = [], [], []\n",
    "            rooms_cnts, options_list, agent_infos = [], [], []\n",
    "            gus, dongs = [], []\n",
    "            posted_ats = []\n",
    "            img_urls = []\n",
    "            areas, directions, approval_dates, parkings, b_types, features, explanations = [], [], [], [], [], [], []\n",
    "            latitudes, longitudes = [], []  # Ï∂îÍ∞Ä\n",
    "\n",
    "            # ÏßÄÏó≠ ÏÑ†ÌÉù Ïû¨ÏßÑÏûÖ\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div/section/div[2]/div[2]/div[1]/div/div/a/span[1]'))).click()\n",
    "            time.sleep(1)\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, '//label[contains(text(), \"ÏÑúÏö∏\")]'))).click()\n",
    "            time.sleep(0.5)\n",
    "            wait.until(EC.element_to_be_clickable((By.XPATH, f'//label[contains(text(), \"{target_gu}\")]'))).click()\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            dong_xpath = f'//label[contains(text(), \"{dong_name}\")]'\n",
    "            try:\n",
    "                dong_element = wait.until(EC.presence_of_element_located((By.XPATH, dong_xpath)))\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", dong_element)\n",
    "                time.sleep(0.5)\n",
    "                dong_element.click()\n",
    "                print(f\"‚úÖ {dong_name} ÌÅ¥Î¶≠ ÏôÑÎ£å\")\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                print(f\"‚ùå {dong_name} ÌÅ¥Î¶≠ Ïã§Ìå®\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                while True:\n",
    "                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                    time.sleep(1.5)\n",
    "                    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                    if new_height == last_height:\n",
    "                        break\n",
    "                    last_height = new_height\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùó Ïä§ÌÅ¨Î°§ Î°úÎî© Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
    "                continue\n",
    "\n",
    "            for idx in range(300):\n",
    "                try:\n",
    "                    listing_elements = driver.find_elements(By.CSS_SELECTOR, \"div.item_inner\")\n",
    "                    if idx >= len(listing_elements):\n",
    "                        print(f\"‚úÖ {dong_name} Îß§Î¨º Î™®Îëê ÌÅ¨Î°§ÎßÅ ÏôÑÎ£å\")\n",
    "                        break\n",
    "\n",
    "                    listing_element = listing_elements[idx]\n",
    "                    print(f\"[{dong_name}] {idx+1}Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ\")\n",
    "\n",
    "                    try:\n",
    "                        naver_btn = listing_element.find_element(By.XPATH, './/a[contains(@class, \"label--cp\")]')\n",
    "                        if naver_btn.is_displayed():\n",
    "                            driver.execute_script(\"arguments[0].scrollIntoView(true);\", naver_btn)\n",
    "                            WebDriverWait(driver, 3).until(EC.element_to_be_clickable(naver_btn)).click()\n",
    "                        else:\n",
    "                            raise Exception(\"Î≤ÑÌäº Ïà®ÍπÄ\")\n",
    "                    except:\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView(true);\", listing_element)\n",
    "                        WebDriverWait(driver, 3).until(EC.element_to_be_clickable(listing_element)).click()\n",
    "\n",
    "                    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.detail_contents\")))\n",
    "\n",
    "                    def text_not_empty(driver):\n",
    "                        try:\n",
    "                            elem = driver.find_element(By.CSS_SELECTOR, \"div.info_title_wrap\")\n",
    "                            return elem.text.strip() if elem.text.strip() else False\n",
    "                        except:\n",
    "                            return False\n",
    "\n",
    "                    title = WebDriverWait(driver, 10).until(text_not_empty)\n",
    "                    titles.append(title)\n",
    "\n",
    "                    try: price = driver.find_element(By.CSS_SELECTOR, \"div.info_article_price\").text.strip()\n",
    "                    except: price = \"Í∞ÄÍ≤© Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    prices.append(price)\n",
    "\n",
    "                    try: address = driver.find_element(By.XPATH, '//th[contains(text(), \"ÏÜåÏû¨ÏßÄ\")]/following-sibling::td').text.strip()\n",
    "                    except: address = \"Ï£ºÏÜå Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    addresses.append(address)\n",
    "\n",
    "                    gus.append(target_gu)\n",
    "                    dongs.append(dong_name)\n",
    "\n",
    "                    try: floor = driver.find_element(By.XPATH, '//th[contains(text(), \"Ìï¥ÎãπÏ∏µ\")]/following-sibling::td[1]').text.strip()\n",
    "                    except: floor = \"Ï∏µÏàò Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    floors.append(floor)\n",
    "\n",
    "                    try: d_type = driver.find_element(By.CSS_SELECTOR, \"div.info_article_price .type\").text.strip()\n",
    "                    except: d_type = \"Íµ¨Î∂Ñ Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    d_types.append(d_type)\n",
    "\n",
    "                    try: area = driver.find_element(By.XPATH, '//th[contains(text(), \"Ï†ÑÏö©Î©¥Ï†Å\")]/following-sibling::td').text.strip()\n",
    "                    except: area = \"Ï†ÑÏö©Î©¥Ï†Å Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    areas.append(area)\n",
    "\n",
    "                    try: feature = driver.find_element(By.XPATH, '//th[contains(text(), \"Îß§Î¨ºÌäπÏßï\")]/following-sibling::td').text.strip()\n",
    "                    except: feature = \"Îß§Î¨º ÌäπÏßï ÏóÜÏùå\"\n",
    "                    features.append(feature)\n",
    "\n",
    "                    try: explanation = driver.find_element(By.XPATH, '//th[contains(text(), \"Îß§Î¨ºÏÑ§Î™Ö\")]/following-sibling::td').text.strip()\n",
    "                    except: explanation = \"Îß§Î¨º ÏÑ§Î™Ö ÏóÜÏùå\"\n",
    "                    explanations.append(explanation)\n",
    "                    \n",
    "                    try: \n",
    "                        b_type = driver.find_element(By.XPATH, '//th[contains(text(), \"Í±¥Ï∂ïÎ¨º Ïö©ÎèÑ\")]/following-sibling::td').text.strip()\n",
    "                    except: b_type = \"Í±¥Ï∂ïÎ¨º Ïö©ÎèÑ Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    b_types.append(b_type)\n",
    "\n",
    "                    try: direction = driver.find_element(By.XPATH, '//th[contains(text(), \"Î∞©Ìñ•\")]/following-sibling::td').text.strip()\n",
    "                    except: direction = \"Î∞©Ìñ• Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    directions.append(direction)\n",
    "\n",
    "                    try: approval_date = driver.find_element(By.XPATH, '//th[contains(text(), \"ÏÇ¨Ïö©ÏäπÏù∏Ïùº\")]/following-sibling::td').text.strip()\n",
    "                    except: approval_date = \"ÏÇ¨Ïö©ÏäπÏù∏Ïùº Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    approval_dates.append(approval_date)\n",
    "\n",
    "                    try: parking_available = driver.find_element(By.XPATH, '//th[contains(text(), \"Ï£ºÏ∞®Í∞ÄÎä•Ïó¨Î∂Ä\")]/following-sibling::td').text.strip()\n",
    "                    except:\n",
    "                        try:\n",
    "                            parking_count = driver.find_element(By.XPATH, '//th[contains(text(), \"Ï¥ùÏ£ºÏ∞®ÎåÄÏàò\")]/following-sibling::td').text.strip()\n",
    "                            parking_available = \"Í∞ÄÎä•\" if parking_count else \"Î∂àÍ∞ÄÎä•\"\n",
    "                        except:\n",
    "                            parking_available = \"Î∂àÍ∞ÄÎä•\"\n",
    "                    parkings.append(parking_available)\n",
    "\n",
    "                    try:\n",
    "                        m_fee_elem = driver.find_element(By.XPATH, '//th[contains(text(), \"Í¥ÄÎ¶¨ÎπÑ\")]/following-sibling::td')\n",
    "                        m_fee_raw = m_fee_elem.text.strip().replace(\"ÏÉÅÏÑ∏Î≥¥Í∏∞\", \"\").strip()\n",
    "\n",
    "                        # Ïò§ÏßÅ Ïà´Ïûê+Îã®ÏúÑ Ìå®ÌÑ¥Îßå Ïú†Ìö®Í∞íÏúºÎ°ú Ïù∏Ï†ï\n",
    "                        if re.fullmatch(r\"\\d+(,\\d+)?(ÎßåÏõê|Ïõê)\", m_fee_raw):\n",
    "                            m_fee = m_fee_raw\n",
    "                        else:\n",
    "                            m_fee = \"Í¥ÄÎ¶¨ÎπÑ Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    except:\n",
    "                        m_fee = \"Í¥ÄÎ¶¨ÎπÑ Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    m_fees.append(m_fee)\n",
    "\n",
    "                    try: a_from = driver.find_element(By.XPATH, '//th[contains(text(), \"ÏûÖÏ£ºÍ∞ÄÎä•Ïùº\")]/following-sibling::td').text.strip()\n",
    "                    except: a_from = \"ÏûÖÏ£ºÍ∞ÄÎä•Ïùº Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    a_froms.append(a_from)\n",
    "\n",
    "                    try: num = driver.find_element(By.XPATH, '//th[contains(text(), \"Îß§Î¨ºÎ≤àÌò∏\")]/following-sibling::td').text.strip()\n",
    "                    except: num = \"Îß§Î¨ºÎ≤àÌò∏ Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    nums.append(num)\n",
    "                    \n",
    "                    try:\n",
    "                        detail = get_detail(num)\n",
    "                        lat = detail.get(\"articleAddition\", {}).get(\"latitude\", \"\")\n",
    "                        lon = detail.get(\"articleAddition\", {}).get(\"longitude\", \"\")\n",
    "                    except:\n",
    "                        lat, lon = \"\", \"\"\n",
    "                    latitudes.append(lat)\n",
    "                    longitudes.append(lon)\n",
    "\n",
    "                    try:\n",
    "                        agent_info = driver.find_element(By.CSS_SELECTOR, \"div.info_agent_title strong.info_title\").text.strip()\n",
    "                    except: agent_info = \"Ï§ëÍ∞úÏÇ¨ Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    agent_infos.append(agent_info)\n",
    "\n",
    "                    try: agent_comm = driver.find_element(By.CSS_SELECTOR, \"strong.point5\").text.strip()\n",
    "                    except: agent_comm = \"Ï§ëÍ∞úÎ£å Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    agent_comms.append(agent_comm)\n",
    "\n",
    "                    try: rooms_cnt = driver.find_element(By.XPATH, '//th[contains(text(), \"Î∞©Ïàò\")]/following-sibling::td').text.strip()\n",
    "                    except: rooms_cnt = \"Î∞© Í∞úÏàò Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    rooms_cnts.append(rooms_cnt)\n",
    "\n",
    "                    try:\n",
    "                        notice_text = driver.find_element(By.CSS_SELECTOR, \"p.info_notice\").text\n",
    "                        date_match = re.search(r\"\\d{4}\\.\\d{2}\\.\\d{2}\", notice_text)\n",
    "                        if date_match:\n",
    "                            posted_date = date_match.group()\n",
    "                        else:\n",
    "                            posted_date = \"ÎÇ†Ïßú ÏóÜÏùå\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"Í≤åÏû¨Ïùº Ï∂îÏ∂ú Ïã§Ìå®: {e}\")\n",
    "                    posted_ats.append(posted_date)\n",
    "\n",
    "                    try:\n",
    "                        option_elements = driver.find_elements(By.CSS_SELECTOR, \"div.option_item_text\")\n",
    "                        options_temp = [elem.text.strip() for elem in option_elements if elem.text.strip()]\n",
    "                        options_str = \", \".join(options_temp) if options_temp else \"ÏòµÏÖò Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "                    except:\n",
    "                        options_str = \"ÏòµÏÖò Ï†ïÎ≥¥ ÏóÜÏùå\"\n",
    "\n",
    "                    options_list.append(options_str)\n",
    "\n",
    "\n",
    "                    img_temp = []\n",
    "                    try:\n",
    "                        tab_buttons = driver.find_elements(By.CSS_SELECTOR, \"button.tab_item\")\n",
    "                        for btn in tab_buttons:\n",
    "                            try:\n",
    "                                span = btn.find_element(By.TAG_NAME, \"span\")\n",
    "                                if \"ÏÇ¨ÏßÑ\" in span.text:\n",
    "                                    btn.click()\n",
    "                                    time.sleep(2)\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "                        photo_elements = driver.find_elements(By.CSS_SELECTOR, \"div.detail_photo_wrap a.detail_photo_item\")\n",
    "                        for elem in photo_elements:\n",
    "                            style = elem.get_attribute(\"style\")\n",
    "                            if \"background-image\" in style:\n",
    "                                start = style.find('url(\"') + len('url(\"')\n",
    "                                end = style.find('\")')\n",
    "                                url = style[start:end]\n",
    "                                img_temp.append(url)\n",
    "                    except:\n",
    "                        pass\n",
    "                    img_urls.append(img_temp)\n",
    "\n",
    "                    try:\n",
    "                        close_btn = WebDriverWait(driver, 3).until(\n",
    "                            EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/div/section/div[2]/div[2]/div/button\"))\n",
    "                        )\n",
    "                        close_btn.click()\n",
    "                        time.sleep(1)\n",
    "                    except:\n",
    "                        print(\"‚ùó Îã´Í∏∞ Î≤ÑÌäº ÏóÜÏùå\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"[{dong_name}] {idx+1}Î≤àÏß∏ Îß§Î¨º ÌÅ¨Î°§ÎßÅ Ïã§Ìå®\")\n",
    "                    traceback.print_exc()\n",
    "                    continue\n",
    "\n",
    "            conn = mysql.connector.connect(\n",
    "                host='127.0.0.1',\n",
    "                user='root',\n",
    "                password='',  \n",
    "                database='real_estate',\n",
    "                charset='utf8mb4'\n",
    "                \n",
    "            )\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS house (\n",
    "                house_id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                title VARCHAR(255) NOT NULL,\n",
    "                price VARCHAR(255) NOT NULL,\n",
    "                address VARCHAR(255) NOT NULL,\n",
    "                floor VARCHAR(255) NOT NULL,\n",
    "                deposit_type VARCHAR(255) NOT NULL,\n",
    "                management_fee VARCHAR(255),\n",
    "                availabe_from VARCHAR(255) NOT NULL,\n",
    "                house_num BIGINT NOT NULL,\n",
    "                agent_comm VARCHAR(255),\n",
    "                agent_info VARCHAR(255) NOT NULL,\n",
    "                rooms_count VARCHAR(255) NOT NULL,\n",
    "                options TEXT,\n",
    "                posted_at varchar(255) NOT NULL,\n",
    "                gu VARCHAR(255) NOT NULL,\n",
    "                dong VARCHAR(255) NOT NULL,\n",
    "                img_url TEXT,\n",
    "                area_size VARCHAR(255) NOT NULL,\n",
    "                direction VARCHAR(255), \n",
    "                built_date VARCHAR(255),  \n",
    "                parking varchar(255) NOT NULL,\n",
    "                building_type VARCHAR(255) NOT NULL,\n",
    "                house_feature TEXT,\n",
    "                house_explanations TEXT,\n",
    "                latitude DOUBLE,\n",
    "                longitude DOUBLE\n",
    "            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "            ''')\n",
    "\n",
    "            # INSERT ÏøºÎ¶¨\n",
    "            for row in zip(\n",
    "                titles, prices, addresses, floors, d_types, m_fees, a_froms,\n",
    "                nums, agent_comms, agent_infos, rooms_cnts, options_list,\n",
    "                posted_ats, gus, dongs, img_urls,\n",
    "                areas, directions, approval_dates, parkings, b_types, features, explanations, latitudes, longitudes\n",
    "            ):\n",
    "                cursor.execute('''\n",
    "                    INSERT INTO house (\n",
    "                        title, price, address, floor, deposit_type, management_fee,\n",
    "                        availabe_from, house_num, agent_comm, agent_info, rooms_count, options,\n",
    "                        posted_at, gu, dong, img_url,\n",
    "                        area_size, direction, built_date, parking, building_type, house_feature, house_explanations,\n",
    "                        latitude, longitude\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ''', (\n",
    "                    row[0], row[1], row[2], row[3], row[4], row[5],\n",
    "                    row[6], row[7], row[8], row[9], row[10], row[11],\n",
    "                    row[12], row[13], row[14], json.dumps(row[15], ensure_ascii=False) if isinstance(row[15], list) else row[15],\n",
    "                    row[16], row[17], row[18], row[19], row[20], row[21], row[22], row[23], row[24]\n",
    "                ))\n",
    "\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print(f\"üíæ {dong_name} DB Ï†ÄÏû• ÏôÑÎ£å\")\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {dong_name} Ï≤òÎ¶¨ Ïã§Ìå®\")\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "# print(len(titles), len(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ïù¥ÎØ∏ÏßÄ S3 ÏóÖÎ°úÎìú\n",
    "# import boto3\n",
    "# import requests\n",
    "# from io import BytesIO\n",
    "\n",
    "# # AWS S3 ÏÑ§Ï†ï\n",
    "# AWS_ACCESS_KEY_ID = \"YOUR_AWS_ACCESS_KEY_ID\"\n",
    "# AWS_SECRET_ACCESS_KEY = \"YOUR_AWS_SECRET_ACCESS_KEY\"\n",
    "# AWS_REGION = \"ap-northeast-2\"  # ÏÑúÏö∏ Î¶¨Ï†Ñ\n",
    "# S3_BUCKET_NAME = \"YOUR_BUCKET_NAME\"\n",
    "\n",
    "# # S3 ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ïó∞Í≤∞\n",
    "# s3_client = boto3.client(\n",
    "#     's3',\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "#     region_name=AWS_REGION\n",
    "# )\n",
    "\n",
    "# def upload_images_for_house(house_num, image_urls):\n",
    "#     uploaded_urls = []\n",
    "    \n",
    "#     for idx, img_url in enumerate(image_urls):\n",
    "#         try:\n",
    "#             # Ïù¥ÎØ∏ÏßÄ Îã§Ïö¥Î°úÎìú\n",
    "#             response = requests.get(img_url)\n",
    "#             response.raise_for_status()\n",
    "            \n",
    "#             # S3Ïóê Ï†ÄÏû•Îê† ÌååÏùºÎ™Ö : Îß§Î¨ºÎ≤àÌò∏_idx+1.jpg\n",
    "#             s3_key = f\"{house_num}_{idx+1}.jpg\"\n",
    "            \n",
    "#             # S3 ÏóÖÎ°úÎìú\n",
    "#             s3_client.upload_fileobj(\n",
    "#                 BytesIO(response.content),\n",
    "#                 S3_BUCKET_NAME,\n",
    "#                 s3_key,\n",
    "#                 ExtraArgs={'ACL': 'public-read', 'ContentType': 'image/jpeg'}\n",
    "#             )\n",
    "            \n",
    "#             # ÏóÖÎ°úÎìúÎêú S3 URL Ï†ÄÏû•\n",
    "#             s3_url = f\"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{s3_key}\"\n",
    "#             uploaded_urls.append(s3_url)\n",
    "            \n",
    "#             print(f\"‚úÖ ÏóÖÎ°úÎìú ÏÑ±Í≥µ: {s3_url}\")\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ùó ÏóÖÎ°úÎìú Ïã§Ìå® ({img_url}): {e}\")\n",
    "#             continue\n",
    "\n",
    "#     return uploaded_urls\n",
    "\n",
    "# # S3Ïóê Ïù¥ÎØ∏ÏßÄ url ÏóÖÎ°úÎìú\n",
    "# for house_num, image_url_list in zip(nums, all_img_urls):\n",
    "#     s3_uploaded_urls = upload_images_for_house(house_num, image_url_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
